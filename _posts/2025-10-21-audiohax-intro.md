---
layout: post
title: "ğŸ™ï¸ AudioHax: Reviving a 15-Year-Old Dream ğŸ™ï¸"
date: 2025-10-21
author: Qweary
categories: [project intro, audiohax, acoustic art]
tags: [audiohax, acoustic art, rust, image, music, midi, fluidsynth, opencv]
permalink: /audiohax-intro.html
---

<pre><code>
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—    â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•
â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• 
â–ˆâ–ˆâ•‘â–„â–„ â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—  â•šâ–ˆâ–ˆâ•”â•  
â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘   
 â•šâ•â•â–€â–€â•â•  â•šâ•â•â•â•šâ•â•â• â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•   â•šâ•â•   
</code></pre>

---

Fifteen years ago, I wasnâ€™t the one writing the code.  
I was the music guy, the consultant, the theory nerd, the one arguing about chord progressions while others hammered C++ into submission at 3 AM.  

The real engine was three friends:  

- **Vince** â€“ the archivist and realist. It turns out he also held on to the files after all these years. One of the greatest friends one could ask for.  
- **Creede** â€“ the thinker and planner. Just last week, he told me he still thinks about the project regularly. One of the kindest people you could hope to know.  
- **Kyle** â€“ the legend. A â€œsuper-coderâ€ who wrote undetectable viruses just to understand them, then deleted them for fun. I always hoped he found a job worthy of that kind of raw skill.  

Back then, we called it **Acoustic Art**. The idea:  

> Take an image â†’ Break it into data â†’ Translate that into music.  

It wasnâ€™t just â€œassign colors to notes.â€ It was deeper: texture, shape, balance, rhythm. A blend of computer vision and music theory, with enough knobs to make each piece unique.  

I kept the code. For a decade and a half, it sat on my drives like a ghost. A project that wouldnâ€™t leave me alone. I didnâ€™t have the skills to resurrect it back then, but I told myself: *One day.*  

Now, one day has arrived.  
I dusted off the old code, rebuilt the vision in Rust, and reimagined what **Acoustic Art** could be with modern tools. When I told my friends I was resurrecting it, it was heartwarming to find out theyâ€™d been thinking about it too.  

---

## ğŸš€ The Present Day  

The project has a new name now: **AudioHax**. And for the first time in 15 years, itâ€™s alive.  

Right now, I can:  

- Take an image  
- Run it through an analysis pipeline  
- Map its features to musical data  
- Output it as MIDI  
- Render it into audio  

Iâ€™ve captured a proof-of-concept video of this exact process, which Iâ€™ll be linking below.  

This isnâ€™t the end goal â€” far from it â€” but itâ€™s a massive milestone.  

---

## ğŸ› ï¸ Currently Implemented  

High-level modules in the current repo:  

- **mapping_loader** â€” loads JSON mapping tables (`assets/mappings.json`) that map visual features (hue ranges, brightness, edge density) to musical modes, chord choices, instrument patches, and velocity/rhythm heuristics.  
- **chord_engine** â€” takes mapping + feature vectors and produces chord progressions and per-instrument note sets. Supports program changes and arpeggiation.  
- **image_source** â€” abstract source model (preselected image path or a camera/source abstraction).  
- **image_analysis** â€” OpenCV-based feature extractor:  
  - Global features (avg hue, edge density, brightness)  
  - Scan-bar features (per-section brightness, hue deltas â†’ mapped to multiple instruments)  
  - Local helpers (histograms, Laplacian variance for texture, edge orientation metrics)  
- **midi_output** â€” wraps `midir` to send program changes, note on/off, and arpeggios.  
- **CLI glue (main.rs)** â€” parses `--instruments` and `play` flags; defaults to `assets/example.jpg` when no path is provided.  

---

## ğŸ§­ The Road Ahead  

Three big steps remain before AudioHax becomes what Iâ€™ve been imagining all these years:  

1. **Music Theory Mapping** â€“ Refine mappings with full integration of key signatures, chord progressions, and stylistic options so the music feels intentional, not random.  
2. **Webcam Integration** â€“ Real-time operation, pulling visual data from a live feed. Imagine standing in an installation space, moving objects around, and hearing the music shift instantly.  
3. **Data Transmission & Decoding** â€“ The â€œHaxâ€ side of AudioHax. Encode data in the music itself, transmit it over an audio channel, and decode it on the other end. Think about data quietly transmitted in everyday sound environments â€” elevators, public transit, coffee shops â€” without anyone realizing it.  

---

## ğŸ’¡ Why It Matters to Me  

This project started as a creative experiment with friends. Now, itâ€™s a blend of art, tech, and security research that perfectly hits all my passions.  

Itâ€™s also proof that some ideas arenâ€™t meant to be abandoned. They just need time, skills, and the right spark to come back to life.  

Next up: building a **custom Rust-based audio modem** â€” a tool that can encode arbitrary data, transmit it over audio, and decode it on the other end. Thatâ€™s going to open up a lot of possibilities, both in art and in security research.  

But first, hereâ€™s the proof-of-concept that started it allâ€¦ again:

<iframe width="560" height="315" src="https://youtube.com/watch?v=q1FtV_WLrAâ€ title="AudioHax music engine version 1" frameborder="0" allowfullscreen></iframe>


